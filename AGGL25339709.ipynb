{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importer les packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importer les modules python nécessaires\n",
    "from itertools import product\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from statistics import mean, stdev\n",
    "import re\n",
    "\n",
    "# Pour lire le fichier fasta\n",
    "from Bio import SeqIO\n",
    "import subprocess\n",
    "\n",
    "# importer numpy\n",
    "import numpy as np\n",
    "\n",
    "# importer les modules scikit-learn nécessaires\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Repliement avec RNAfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def executer_rnafold(fichier_fasta, fichier_output):\n",
    "    # opening the fasta file\n",
    "\n",
    "    with open(fichier_output, \"w\") as output_file:\n",
    "        for seq_record in SeqIO.parse(fichier_fasta, \"fasta\"):\n",
    "            # extracting the sequence (.seq)\n",
    "            sequence = str(seq_record.seq)\n",
    "            # 1. Lancer RNAfold et récupérer son output stdout dans la variable string repliement_fasta.\n",
    "            process = subprocess.Popen(['RNAfold'], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "            [stdout, stderr] = process.communicate(input=sequence)\n",
    "            # Write the sequence name (.id)\n",
    "            output_file.write(f\">{seq_record.id}\\n\")\n",
    "            # 2. Enregistrer repliement_fasta dans le fichier fichier_output\n",
    "            output_file.write(f\"{stdout.split()[0]}\\n{stdout.split()[1]}\\n\")\n",
    "        \n",
    "        # print(f\"{stdout.split()[0]}\\n{stdout.split()[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our given fasta file in a list \n",
    "fasta_files = [\"Fasta/hsa_hairpin.fasta\", \"Fasta/hsa_hairpin_neg1.fasta\", \"Fasta/hsa_hairpin_neg2.fasta\"]\n",
    "# looping through the files to get the folds files\n",
    "for file in fasta_files :\n",
    "    # make the name of the output file from its input file\n",
    "    file_output = f\"Fasta/repliments/{file.split('/')[1].split('.')[0]}_fold.fasta\"\n",
    "    # check if the output file exist \n",
    "    if not os.path.isfile(file_output):\n",
    "        executer_rnafold(file, file_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traiter_fasta_fold(fichier_fold):\n",
    "    \n",
    "    repliments = defaultdict(list)\n",
    "\n",
    "    # 1. Lire le fichier fichier_fold et récupérer son contenu dans une liste lignes\n",
    "    with open(fichier_fold, 'r') as file:\n",
    "        lignes = file.readlines()\n",
    "\n",
    "    # supprimer \"\\n\" à la fin des lignes\n",
    "    lignes_n = [ligne.strip() for ligne in lignes]\n",
    "\n",
    "    # 2. Traiter repliement_fasta pour créer un dictionnaire de listes defaultdict(list)\n",
    "    i = 0\n",
    "    while i < len(lignes_n):\n",
    "        # si la ligne commence par '>' donc on est au debut du nom de la sequence\n",
    "        if lignes_n[i].startswith('>'):\n",
    "            nom_sequence = lignes_n[i][1:]\n",
    "            # mettre en lowercase\n",
    "            sequence = lignes_n[i+1].lower()\n",
    "            structure = lignes_n[i+2]\n",
    "            # enregistrer les sequences et structures dans le dictionnaire\n",
    "            repliments[nom_sequence] = [sequence, structure]\n",
    "            # saut de 3 lignes : nom + sequence + repliement\n",
    "            i += 3\n",
    "        else:\n",
    "        # sinon saut d'une ligne jusqu'a trouver le '>' du debut\n",
    "            i += 1\n",
    "\n",
    "    return repliments\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adresse fichier des repliments \n",
    "output_path = \"Fasta/repliments/\"\n",
    "# pour tester la fonction traiter_fasta_fold() \n",
    "# j'ai opter pour un dictionnaire qui contient les noms des fichiers output comme cle et le dictionnaire generer par la fonction comme valeur\n",
    "\n",
    "repliments = defaultdict()\n",
    "\n",
    "for file in os.listdir(output_path):\n",
    "    # On extrait les cles du nom de leur fichier respective\n",
    "    name = f\"dict{file.split('hairpin')[1].split('.fasta')[0]}\"\n",
    "    # print(f\"dict{file.split('hairpin')[1].split('.fasta')[0]}\")\n",
    "    repliments[name] = traiter_fasta_fold(f\"{output_path}{file}\")\n",
    "    \n",
    "# repliments.keys()\n",
    "# repliments.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Calcul du nombre d’occurrences des triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ne pas modifier la fonction!\n",
    "\n",
    "def get_all_triplets():    \n",
    "\n",
    "    db = [\"...\", \"..(\", \".((\", \"(((\", \"((.\", \"(..\", \"(.(\", \".(.\"]\n",
    "    nd = [\"a\", \"c\", \"g\", \"u\"]\n",
    "\n",
    "    return [i+j for i,j in product(nd, db)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generer les sequences RNA et leur structures\n",
    "triplets = get_all_triplets()\n",
    "# triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ne pas modifier la fonction!\n",
    "\n",
    "\n",
    "def get_seq_triplets(sequence, structure):\n",
    "   \n",
    "    seq_triplets = defaultdict(int)\n",
    "\n",
    "    assert len(sequence) == len(structure)\n",
    "\n",
    "    struct = re.sub(\"\\)\", \"(\", structure)\n",
    "\n",
    "    seq_tab = list(sequence)\n",
    "    stc_tab = list(struct)\n",
    "\n",
    "    for ind in range(len(seq_tab)):\n",
    "        if ind == 0: \n",
    "            before = \".\"\n",
    "        else: \n",
    "            before = stc_tab[ind-1]\n",
    "\n",
    "        midlle = stc_tab[ind]\n",
    "\n",
    "        if ind == len(seq_tab)-1: \n",
    "            after = \".\"\n",
    "        else:\n",
    "            after = stc_tab[ind+1]\n",
    "\n",
    "        triplet = seq_tab[ind] + before + midlle + after\n",
    "        seq_triplets[triplet] += 1\n",
    "\n",
    "    return seq_triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_triplets = defaultdict()\n",
    "# Calculer les occurences des triplets dans les sequences et structures\n",
    "for repliment, name in zip(repliments.values(), repliments.keys()) :\n",
    "    # print(repliment)\n",
    "    # print(name)\n",
    "    for sequence, structure in repliment.values():\n",
    "        seq_triplets[name] = get_seq_triplets(sequence, structure)\n",
    "        #print(f\"Occurrences of triplets in sequence {sequence}: {seq_triplets}\")\n",
    "# seq_triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ne pas modifier la fonction!\n",
    "\n",
    "def calculer_Xu_triplets(repliements):\n",
    "   \n",
    "    liste_triplets = get_all_triplets()\n",
    "\n",
    "    nb_sequences = len(repliements)\n",
    "    nb_triplets = len(liste_triplets)\n",
    "\n",
    "    triplets = np.zeros((nb_sequences, nb_triplets))\n",
    "    \n",
    "    for i, nom in enumerate(repliements):\n",
    "        seq_triplets = get_seq_triplets(repliements[nom][0], repliements[nom][1])\n",
    "        \n",
    "        for j, triplet in enumerate(liste_triplets):\n",
    "            if triplet in seq_triplets:\n",
    "                triplets[i, j] = seq_triplets[triplet]\n",
    "    \n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dict_fold', 'dict_neg1_fold', 'dict_neg2_fold'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Xu_triplets = defaultdict()\n",
    "for repliment, name in zip( repliments.values(), repliments.keys() ):\n",
    "    #print(name)\n",
    "    Xu_triplets[name] = calculer_Xu_triplets(repliment)\n",
    "Xu_triplets.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Construction du jeu de données d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def construire_dataset(data1, data2):\n",
    "        \n",
    "    # 1. Construire X\n",
    "\n",
    "    X = np.concatenate((data1, data2), axis=0)\n",
    "   \n",
    "    # 2. Mettre à l'échelle les valeurs de X entre 0 et 1 avec la méthode min-max\n",
    "    X_min = X.min(axis=0)\n",
    "    X_max = X.max(axis=0)\n",
    "    X = (X - X_min) / (X_max - X_min)\n",
    "\n",
    "    # 3. Construire y\n",
    "    # Étiquettes des instances de data1 = 0\n",
    "    # Étiquettes des instances de data2 = 1\n",
    "    y = np.concatenate((np.zeros(data1.shape[0]), np.ones(data2.shape[0])))\n",
    "\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = construire_dataset(Xu_triplets[\"dict_fold\"], Xu_triplets[\"dict_neg1_fold\"])\n",
    "#x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Évaluation et entrainement des modèles supervisés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction evaluer_cv_entrainer() en utilsant cross_validate()\n",
    "\n",
    "def evaluer_cv_entrainer(x, y, cv, modele=\"lsvc\", mesure='f1_weighted'):\n",
    "    \n",
    "    # Modèles acceptés :\n",
    "    modeles = {\n",
    "        \"lsvc\": SVC(kernel='linear'),\n",
    "        \"nsvc\": SVC(kernel='rbf'),\n",
    "        \"mnb\": MultinomialNB(),\n",
    "        \"gnb\": GaussianNB(),\n",
    "        \"dtc\": DecisionTreeClassifier()\n",
    "    }\n",
    "    \n",
    "    if modele not in modeles:\n",
    "        print(\"Type de modele {} est invalide\".format(modele))\n",
    "        modele = \"lsvc\"\n",
    "        print(\"Le modele {} sera entrainé\".format(modele))\n",
    "    \n",
    "    # 1. Initialiser une instance de classifieur selon la valeur de modele\n",
    "    classifieur = modeles[modele]\n",
    "    \n",
    "    # 2. Calculer les scores de validation croisée du classifieur avec X et y\n",
    "    scorer = make_scorer(f1_score, average=mesure)\n",
    "    scores = cross_val_score(classifieur, x, y, cv=cv, scoring=scorer)\n",
    "    \n",
    "    # 3. Entrainer le classifieur avec X et y\n",
    "    classifieur.fit(x, y)\n",
    "      \n",
    "    return scores, classifieur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction evaluer_cv_entrainer() en utilsant cross_validate() \n",
    "\n",
    "def evaluer_cv_entrainer1(X, y, cv=5, modele=\"lsvc\", mesure='f1_weighted'):\n",
    "    if modele == \"lsvc\":\n",
    "        classifieur = SVC(kernel='linear')\n",
    "    elif modele == \"nsvc\":\n",
    "        classifieur = SVC(kernel='rbf')\n",
    "    elif modele == \"mnb\":\n",
    "        classifieur = MultinomialNB()\n",
    "    elif modele == \"gnb\":\n",
    "        classifieur = GaussianNB()\n",
    "    elif modele == \"dtc\":\n",
    "        classifieur = DecisionTreeClassifier()\n",
    "\n",
    "    scoring = make_scorer(f1_score, average='weighted')\n",
    "    scores = cross_validate(classifieur, X, y, cv=cv, scoring=scoring)\n",
    "\n",
    "    classifieur.fit(X, y)\n",
    "\n",
    "    return scores, classifieur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cross_val_score, lsvc: [0.94047091 0.93463247 0.92670051 0.93000761 0.95218656]\n",
      "using cross_validate, lsvc: [0.94047091 0.93463247 0.92670051 0.93000761 0.95218656]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' scores1, classifieur1 = evaluer_cv_entrainer1(x, y, cv=5, modele=\"nsvc\", mesure=\\'f1_weighted\\')\\nprint(f\"using cross_validate, nsvc: {scores1[\\'test_score\\']}\")\\nscores1, classifieur1 = evaluer_cv_entrainer1(x, y, cv=5, modele=\"mnb\", mesure=\\'f1_weighted\\')\\nprint(f\"using cross_validate, mnb: {scores1[\\'test_score\\']}\")\\nscores1, classifieur1 = evaluer_cv_entrainer1(x, y, cv=5, modele=\"gnb\", mesure=\\'f1_weighted\\')\\nprint(f\"using cross_validate, gnb: {scores1[\\'test_score\\']}\")\\nscores1, classifieur1 = evaluer_cv_entrainer1(x, y, cv=5, modele=\"dtc\", mesure=\\'f1_weighted\\')\\nprint(f\"using cross_validate, dtc: {scores1[\\'test_score\\']}\") '"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Évaluer et entraîner un classifieur avec validation croisée en utilisant la fonction cross_val_score\n",
    "scores, classifieur = evaluer_cv_entrainer(x, y, cv=5, modele=\"lsvc\", mesure='weighted')\n",
    "print(f\"using cross_val_score, lsvc: {scores}\")\n",
    "\n",
    "\"\"\" scores, classifieur = evaluer_cv_entrainer(x, y, cv=5, modele=\"nsvc\", mesure='weighted')\n",
    "print(f\"using cross_val_score, nsvc: {scores}\")\n",
    "scores, classifieur = evaluer_cv_entrainer(x, y, cv=5, modele=\"mnb\", mesure='weighted')\n",
    "print(f\"using cross_val_score, mnb: {scores}\")\n",
    "scores, classifieur = evaluer_cv_entrainer(x, y, cv=5, modele=\"gnb\", mesure='weighted')\n",
    "print(f\"using cross_val_score, gnb: {scores}\")\n",
    "scores, classifieur = evaluer_cv_entrainer(x, y, cv=5, modele=\"dtc\", mesure='weighted')\n",
    "print(f\"using cross_val_score, dtc: {scores}\") \"\"\"\n",
    "\n",
    "# Évaluer et entraîner un classifieur avec validation croisée en utilisant la fonction cross_validate\n",
    "scores1, classifieur1 = evaluer_cv_entrainer1(x, y, cv=5, modele=\"lsvc\", mesure='f1_weighted')\n",
    "print(f\"using cross_validate, lsvc: {scores1['test_score']}\")\n",
    "\n",
    "\"\"\" scores1, classifieur1 = evaluer_cv_entrainer1(x, y, cv=5, modele=\"nsvc\", mesure='f1_weighted')\n",
    "print(f\"using cross_validate, nsvc: {scores1['test_score']}\")\n",
    "scores1, classifieur1 = evaluer_cv_entrainer1(x, y, cv=5, modele=\"mnb\", mesure='f1_weighted')\n",
    "print(f\"using cross_validate, mnb: {scores1['test_score']}\")\n",
    "scores1, classifieur1 = evaluer_cv_entrainer1(x, y, cv=5, modele=\"gnb\", mesure='f1_weighted')\n",
    "print(f\"using cross_validate, gnb: {scores1['test_score']}\")\n",
    "scores1, classifieur1 = evaluer_cv_entrainer1(x, y, cv=5, modele=\"dtc\", mesure='f1_weighted')\n",
    "print(f\"using cross_validate, dtc: {scores1['test_score']}\") \"\"\"\n",
    "# classifieur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Fonction principale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def entrainer_par_triplets(\n",
    "    fasta_seq_pos,\n",
    "    fasta_fold_pos,\n",
    "    fasta_seq_neg,\n",
    "    fasta_fold_neg,\n",
    "    cv,\n",
    "    modele=\"lsvc\",\n",
    "    mesure=\"f1_weighted\"):\n",
    "    \n",
    "\n",
    "    ## 1. Replier les séquences du set positif\n",
    "    # Replier les séquences si le fichier fasta_fold_pos n'existe pas\n",
    "    if not os.path.isfile(fasta_fold_pos):\n",
    "        executer_rnafold(fasta_seq_pos, fasta_fold_pos)\n",
    "    \n",
    "    ## 2. Replier les séquences du set négatif\n",
    "    # Replier les séquences si le fichier fasta_fold_neg n'existe pas\n",
    "    if not os.path.isfile(fasta_fold_neg):\n",
    "        executer_rnafold(fasta_seq_neg, fasta_fold_neg)\n",
    "\n",
    "\n",
    "    ## 3. Traiter les repliements du set positif \n",
    "    repliements_pos = traiter_fasta_fold(fasta_fold_pos)\n",
    "\n",
    "    ## 4. Traiter les repliements du set négatif\n",
    "    repliements_neg1 = traiter_fasta_fold(fasta_fold_neg)\n",
    "\n",
    "    ## 5. Calculer les triplets du set positif\n",
    "    triplets_pos = calculer_Xu_triplets(repliements_pos)\n",
    "\n",
    "    ## 6. Calculer les triplets du set négatif\n",
    "    triplets_neg1 = calculer_Xu_triplets(repliements_neg1)\n",
    "\n",
    "    ## 7. Construire le jeu d'entrainement X et y\n",
    "    x, y = construire_dataset(triplets_pos, triplets_neg1)\n",
    "\n",
    "    ## 8. Évaluer et entrainer le classifieur avec validation croisée\n",
    "    scores, classifieur = evaluer_cv_entrainer1(x, y, cv=5, modele=\"lsvc\", mesure='f1_weighted')\n",
    "\n",
    "\n",
    "    return scores, classifieur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94047091, 0.93463247, 0.92670051, 0.93000761, 0.95218656])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cette cellule est dédiée pour tester entrainer_par_triplets()\n",
    "fasta_seq_pos = \"Fasta/hsa_hairpin.fasta\"\n",
    "fasta_fold_pos = \"Fasta/repliments/hsa_hairpin_fold.fasta\"\n",
    "fasta_seq_neg = \"Fasta/hsa_hairpin_neg1.fasta\"\n",
    "fasta_fold_neg = \"Fasta/repliments/hsa_hairpin_neg1_fold.fasta\"\n",
    "scores, classifieur = entrainer_par_triplets(\n",
    "                            fasta_seq_pos,\n",
    "                            fasta_fold_pos,\n",
    "                            fasta_seq_neg,\n",
    "                            fasta_fold_neg,\n",
    "                            cv=10,\n",
    "                            modele=\"lsvc\",\n",
    "                            mesure=\"f1_weighted\")\n",
    "scores['test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Comparaison des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def comparer_modeles(\n",
    "    fasta_seq_pos,\n",
    "    fasta_fold_pos,\n",
    "    fasta_seq_neg,\n",
    "    fasta_fold_neg,\n",
    "    cv,\n",
    "    modeles=[\"lsvc\", \"nsvc\", \"mnb\", \"gnb\", \"dtc\"],\n",
    "    mesure=\"f1_weighted\"):\n",
    "\n",
    "    moyennes = []\n",
    "    ecarts_types = []\n",
    "\n",
    "    for modele in modeles:\n",
    "        scores, _ = entrainer_par_triplets(fasta_seq_pos, fasta_fold_pos, fasta_seq_neg, fasta_fold_neg, cv, modele, mesure)\n",
    "        # print(\"is it here : \", scores)\n",
    "        moyennes.append(mean(scores['test_score']))\n",
    "        ecarts_types.append(stdev(scores['test_score']))\n",
    "        \n",
    "    return moyennes, ecarts_types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moyennes :  [0.9367996124171492, 0.9367996124171492, 0.9367996124171492, 0.9367996124171492, 0.9367996124171492]\n",
      "Ecarts types :  [0.01003812797593524, 0.01003812797593524, 0.01003812797593524, 0.01003812797593524, 0.01003812797593524]\n"
     ]
    }
   ],
   "source": [
    "moyennes, ecarts_types = comparer_modeles(\n",
    "                            fasta_seq_pos,\n",
    "                            fasta_fold_pos,\n",
    "                            fasta_seq_neg,\n",
    "                            fasta_fold_neg,\n",
    "                            cv=10,\n",
    "                            modeles=[\"lsvc\", \"nsvc\", \"mnb\", \"gnb\", \"dtc\"],\n",
    "                            mesure=\"f1_weighted\")\n",
    "print('Moyennes : ',moyennes)\n",
    "print('Ecarts types : ',ecarts_types)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.1 Comparer les modèles avec les précurseurs de l'humain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèles à comparer :\n",
    "comp_modeles = [\"lsvc\", \"nsvc\", \"mnb\", \"gnb\", \"dtc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_weighted de 10-fold validations croisées des modèles :\n",
      "\n",
      "modèle\t: mean\tstd\n",
      "lsvc\t: 0.937\t0.010\n",
      "nsvc\t: 0.937\t0.010\n",
      "mnb\t: 0.937\t0.010\n",
      "gnb\t: 0.937\t0.010\n",
      "dtc\t: 0.937\t0.010\n"
     ]
    }
   ],
   "source": [
    "# Jeu de données 1\n",
    "# ################\n",
    "# séquences du set négatif générées par brassage aléatoire des nucléotides des séquences réelles\n",
    "\n",
    "seq_pos = \"Fasta/hsa_hairpin.fasta\"\n",
    "fold_pos = \"Fasta/repliments/hsa_hairpin_fold.fasta\"\n",
    "\n",
    "seq_neg = \"Fasta/hsa_hairpin_neg1.fasta\"\n",
    "fold_neg = \"Fasta/repliments/hsa_hairpin_neg1_fold.fasta\"\n",
    "\n",
    "cv_iterations = 10\n",
    "mesure_cv = \"f1_weighted\"\n",
    "\n",
    "# Comparaison des modèles\n",
    "moyennes, ecarts_types = comparer_modeles(seq_pos, fold_pos, seq_neg, fold_neg, cv_iterations)\n",
    "\n",
    "print(\"{} de {}-fold validations croisées des modèles :\\n\".format(mesure_cv, cv_iterations))\n",
    "print(\"modèle\\t: mean\\tstd\")\n",
    "\n",
    "for i, modele in enumerate(comp_modeles):\n",
    "    print(\"{}\\t: {:.3f}\\t{:.3f}\".format(modele, moyennes[i], ecarts_types[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_weighted de 10-fold validations croisées des modèles :\n",
      "\n",
      "modèle\t: mean\tstd\n",
      "lsvc\t: 0.884\t0.002\n",
      "nsvc\t: 0.884\t0.002\n",
      "mnb\t: 0.884\t0.002\n",
      "gnb\t: 0.884\t0.002\n",
      "dtc\t: 0.884\t0.002\n"
     ]
    }
   ],
   "source": [
    "# Jeu de données 2\n",
    "# ################\n",
    "# séquences du set négatif générées par relocalisation de sous-séquences dans les séquences réelles\n",
    "\n",
    "seq_pos = \"Fasta/hsa_hairpin.fasta\"\n",
    "fold_pos = \"Fasta/repliments/hsa_hairpin_fold.fasta\"\n",
    "\n",
    "seq_neg = \"Fasta/hsa_hairpin_neg2.fasta\"\n",
    "fold_neg = \"Fasta/repliments/hsa_hairpin_neg2_fold.fasta\"\n",
    "\n",
    "cv_iterations = 10\n",
    "mesure_cv = \"f1_weighted\"\n",
    "\n",
    "# Comparaison des modèles\n",
    "moyennes, ecarts_types = comparer_modeles(seq_pos, fold_pos, seq_neg, fold_neg, cv_iterations)\n",
    "\n",
    "print(\"{} de {}-fold validations croisées des modèles :\\n\".format(mesure_cv, cv_iterations))\n",
    "print(\"modèle\\t: mean\\tstd\")\n",
    "\n",
    "for i, modele in enumerate(comp_modeles):\n",
    "    print(\"{}\\t: {:.3f}\\t{:.3f}\".format(modele, moyennes[i], ecarts_types[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question :\n",
    "    Quelle méthode et quels modèles sont les plus efficaces pour discriminer entre les précurseurs réels et les pseudo-précurseurs ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.2 Comparer les modèles avec les précuseurs des animaux et des plantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_weighted de 10-fold validations croisées des modèles :\n",
      "\n",
      "modèle\t: mean\tstd\n",
      "lsvc\t: 0.700\t0.115\n",
      "nsvc\t: 0.700\t0.115\n",
      "mnb\t: 0.700\t0.115\n",
      "gnb\t: 0.700\t0.115\n",
      "dtc\t: 0.700\t0.115\n"
     ]
    }
   ],
   "source": [
    "# Jeu de donnée 3\n",
    "# ################\n",
    "\n",
    "#seq_pos = \"Fasta/Animal/bos_taurus_hairpin.fasta\"\n",
    "#fold_pos = \"Fasta/Animal/repliments/bos_taurus_hairpin_fold.fasta\"\n",
    "\n",
    "seq_pos = \"Fasta/Animal/animal_hairpin.fasta\"\n",
    "fold_pos = \"Fasta/Animal/repliments/animal_hairpin_fold.fasta\"\n",
    "\n",
    "seq_neg = \"Fasta/Plant/arabidopsis_thaliana_miRna.fasta\"\n",
    "fold_neg = \"Fasta/Plant/repliments/arabidopsis_thaliana_miRna_fold.fa\"\n",
    "\n",
    "cv_iterations = 10\n",
    "mesure_cv = \"f1_weighted\"\n",
    "\n",
    "\n",
    "# Comparaison des modèles\n",
    "moyennes, ecarts_types = comparer_modeles(seq_pos, fold_pos, seq_neg, fold_neg, cv_iterations)\n",
    "\n",
    "print(\"{} de {}-fold validations croisées des modèles :\\n\".format(mesure_cv, cv_iterations))\n",
    "print(\"modèle\\t: mean\\tstd\")\n",
    "\n",
    "for i, modele in enumerate(comp_modeles):\n",
    "    print(\"{}\\t: {:.3f}\\t{:.3f}\".format(modele, moyennes[i], ecarts_types[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question\n",
    "Les modèles entrainés avec les triplets peuvent-ils faire la discrimination entre les précurseurs des animaux et ceux des plantes ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
